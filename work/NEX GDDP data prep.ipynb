{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gdal\n",
    "from osgeo import osr\n",
    "import sys\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = list(filter(lambda x: x.endswith('.nc'), os.listdir('./data')))\n",
    "# filenames = filenames[0:3]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prefix=\"data\"\n",
    "\n",
    "def get_file(var, scenario, model, year, **kwargs):\n",
    "    filename = var + \"_day_BCSD_\" + scenario + \"_r1i1p1_\" + model + \"_\" + year + \".nc\"\n",
    "    filename = kwargs.get(\"prefix\") + \"/\" + filename if kwargs.get('prefix') else filename\n",
    "    print(filename)\n",
    "    dataset = xr.open_dataset(filename)\n",
    "    return dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tmax90F(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"tasmax\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x > 305.372).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(tmax90F(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tmax95F(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"tasmax\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x > 308.150).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(tmax95F(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tmax100F(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"tasmax\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x > 310.928).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(tmax100F(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def icing_days(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"tasmax\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x < 273.150).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(icing_days(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def frost_days(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"tasmin\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x < 273.150).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(frost_days(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentile99(var, scenario, model, year, **kwargs):\n",
    "    dataset = get_file(var, scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: np.percentile(x, 99), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(percentile99(\"tasmin\", \"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentile1(var, scenario, model, year, **kwargs):\n",
    "    dataset = get_file(var, scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: np.percentile(x, 1), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(percentile1(\"tasmin\", \"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pr2in(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"pr\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x > 0.0005879).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(pr2in(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pr3in(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"pr\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x > 0.0008819).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(pr3in(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pr4in(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"pr\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    result = np.apply_along_axis(lambda x: (x > 0.0011759).sum(), 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(pr4in(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consecDD(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"pr\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    def calc(data_values):\n",
    "        cdd_count = 0\n",
    "        max_count = 0\n",
    "        for value in data_values:\n",
    "            if value < 0.0000029398:\n",
    "                cdd_count = cdd_count + 1\n",
    "                if cdd_count > max_count:\n",
    "                    max_count = cdd_count\n",
    "            else:\n",
    "                cdd_count = 0\n",
    "        return max_count\n",
    "    result = np.apply_along_axis(calc, 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(consecDD(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consecWD(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"pr\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    def calc(data_values):\n",
    "        cwd_count = 0\n",
    "        max_count = 0\n",
    "        for value in data_values:\n",
    "            if value >= 0.0000029398:\n",
    "                cwd_count = cwd_count + 1\n",
    "                if cwd_count > max_count:\n",
    "                    max_count = cwd_count\n",
    "            else:\n",
    "                cwd_count = 0\n",
    "        return max_count\n",
    "    result = np.apply_along_axis(calc, 1, data_array)\n",
    "    return result\n",
    "\n",
    "plt.imshow(np.squeeze(consecWD(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tmax5day(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"tasmax\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    def moving_average(a, n=5):\n",
    "        ret = np.cumsum(a, dtype=float)\n",
    "        ret[n:] = ret[n:] - ret[:-n]\n",
    "        return ret[n - 1:] / n\n",
    "    moving_averages = np.apply_along_axis(moving_average, 1, data_array)\n",
    "    max_temps =       np.apply_along_axis(np.amax, 1, moving_averages)\n",
    "    return max_temps\n",
    "    \n",
    "plt.imshow(np.squeeze(tmax5day(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tmin5day(scenario, model, year, **kwargs):\n",
    "    dataset = get_file(\"tasmin\", scenario, model, year, prefix = kwargs.get('prefix'))\n",
    "    data_array = dataset.to_array()\n",
    "    def moving_average(a, n=5):\n",
    "        ret = np.cumsum(a, dtype=float)\n",
    "        ret[n:] = ret[n:] - ret[:-n]\n",
    "        return ret[n - 1:] / n\n",
    "    moving_averages = np.apply_along_axis(moving_average, 1, data_array)\n",
    "    min_temps =       np.apply_along_axis(np.amin, 1, moving_averages)\n",
    "    return min_temps\n",
    "    \n",
    "%timeit plt.imshow(np.squeeze(tmin5day(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gdal\n",
    "from osgeo import osr\n",
    "import sys\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "from itertools import groupby\n",
    "import matplotlib.pyplot as plt\n",
    "import gdal\n",
    "\n",
    "prefix=\"data\"\n",
    "\n",
    "def get_file(var, scenario, model, year, **kwargs):\n",
    "    filename = var + \"_day_BCSD_\" + scenario + \"_r1i1p1_\" + model + \"_\" + year + \".nc\"\n",
    "    filename = kwargs.get(\"prefix\") + \"/\" + filename if kwargs.get('prefix') else filename\n",
    "    print(filename)\n",
    "    dataset = xr.open_dataset(filename)\n",
    "    return dataset\n",
    "\n",
    "def calc_cdd(data_values):\n",
    "    cdd_count = 0\n",
    "    max_count = 0\n",
    "    for value in data_values:\n",
    "        if value < 0.0000029398:\n",
    "            cdd_count = cdd_count + 1\n",
    "            if cdd_count > max_count:\n",
    "                max_count = cdd_count\n",
    "        else:\n",
    "            cdd_count = 0\n",
    "    return max_count\n",
    "\n",
    "def calc_cwd(data_values):\n",
    "    cwd_count = 0\n",
    "    max_count = 0\n",
    "    for value in data_values:\n",
    "        if value >= 0.0000029398:\n",
    "            cwd_count = cwd_count + 1\n",
    "            if cwd_count > max_count:\n",
    "                max_count = cwd_count\n",
    "        else:\n",
    "            cwd_count = 0\n",
    "    return max_count\n",
    "\n",
    "def moving_average(a, n=5):\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n\n",
    "\n",
    "def cut_and_paste(raster):\n",
    "    cut = np.split(np.squeeze(raster), 2, axis = 1)\n",
    "    paste = np.concatenate((cut[1], cut[0]), axis = 1)\n",
    "    return paste\n",
    "\n",
    "def calc(scenario, model, year, **kwargs):\n",
    "    print(\"Getting files for year \" + year)\n",
    "    dataset_tasmin = get_file(\"tasmin\", scenario, model, year, prefix=kwargs.get('prefix'))\n",
    "    dataset_tasmax = get_file(\"tasmax\", scenario, model, year, prefix=kwargs.get('prefix'))\n",
    "    dataset_pr     = get_file(\"pr\", scenario, model, year, prefix=kwargs.get('prefix'))\n",
    "    \n",
    "    print(\"Extracting data\")\n",
    "    array_tasmin = dataset_tasmin.to_array()\n",
    "    array_tasmax = dataset_tasmax.to_array()\n",
    "    array_pr     = dataset_pr.to_array()\n",
    "    \n",
    "    print(\"Index calc\")\n",
    "    \n",
    "    print(\"tmax90F\")\n",
    "    tmax90F = np.apply_along_axis(lambda x: (x > 305.372).sum(), 1, array_tasmax)\n",
    "    \n",
    "    print(\"tmax95F\")\n",
    "    tmax95F = np.apply_along_axis(lambda x: (x > 308.150).sum(), 1, array_tasmax)\n",
    "    \n",
    "    print(\"tmax100F\")\n",
    "    tmax100F = np.apply_along_axis(lambda x: (x > 310.928).sum(), 1, array_tasmax)\n",
    "\n",
    "    print(\"icing_days\")\n",
    "    icing_days = np.apply_along_axis(lambda x: (x < 273.150).sum(), 1, array_tasmax)\n",
    "    \n",
    "    print(\"frost_days\")\n",
    "    frost_days = np.apply_along_axis(lambda x: (x < 273.150).sum(), 1, array_tasmin)\n",
    "    \n",
    "    print(\"pr2in\")\n",
    "    pr2in = np.apply_along_axis(lambda x: (x > 0.0005879).sum(), 1, array_pr)\n",
    "    \n",
    "    print(\"pr3in\")\n",
    "    pr3in = np.apply_along_axis(lambda x: (x > 0.0008819).sum(), 1, array_pr)\n",
    "    \n",
    "    print(\"pr4in\")\n",
    "    pr4in = np.apply_along_axis(lambda x: (x > 0.0011759).sum(), 1, array_pr)\n",
    "    \n",
    "    print(\"cdd\")\n",
    "    cdd = np.apply_along_axis(lambda x: calc_cdd(x), 1, array_pr)\n",
    "    \n",
    "    print(\"cwd\")\n",
    "    cwd = np.apply_along_axis(lambda x: calc_cwd(x), 1, array_pr)\n",
    "    \n",
    "    print(\"tmax5day\")\n",
    "    tasmax_moving_averages = np.apply_along_axis(moving_average, 1, array_tasmax)\n",
    "    tmax5day = np.apply_along_axis(np.amax, 1, tasmax_moving_averages)\n",
    "    \n",
    "    print(\"tmin5day\")\n",
    "    tasmin_moving_averages = np.apply_along_axis(moving_average, 1, array_tasmin)\n",
    "    tmin5day = np.apply_along_axis(np.amax, 1, tasmin_moving_averages)\n",
    "    \n",
    "    print(\"tmax99p\")\n",
    "    tmax99p = np.apply_along_axis(lambda x: np.percentile(x, 99), 1, array_tasmax)\n",
    "    \n",
    "    print(\"tmax1p\")\n",
    "    tmax1p = np.apply_along_axis(lambda x: np.percentile(x, 1), 1, array_tasmax)\n",
    "    \n",
    "    print(\"tmin99p\")\n",
    "    tmin99p = np.apply_along_axis(lambda x: np.percentile(x, 99), 1, array_tasmin)\n",
    "    \n",
    "    print(\"tmin1p\")\n",
    "    tmin1p = np.apply_along_axis(lambda x: np.percentile(x, 1), 1, array_tasmin)\n",
    "    \n",
    "    print(\"pr99p\")\n",
    "    pr99p = np.apply_along_axis(lambda x: np.percentile(x, 99), 1, array_pr)\n",
    "    \n",
    "    print(\"pr1p\")\n",
    "    pr1p = np.apply_along_axis(lambda x: np.percentile(x, 1), 1, array_pr)\n",
    "    \n",
    "    print(\"prmaxday\")\n",
    "    prmaxday = np.apply_along_axis(lambda x: np.amax(x) * 86400, 1, array_pr)\n",
    "    \n",
    "    processed_arrays = np.stack((\n",
    "        tmax90F,\n",
    "        tmax95F,\n",
    "        tmax100F,\n",
    "        icing_days,\n",
    "        frost_days,\n",
    "        pr2in,\n",
    "        pr3in,\n",
    "        pr4in,\n",
    "        cdd,\n",
    "        cwd,\n",
    "        tmax5day,\n",
    "        tmin5day,\n",
    "        tmax99p,\n",
    "        tmax1p,\n",
    "        tmin99p,\n",
    "        tmin1p,\n",
    "        pr99p,\n",
    "        pr1p,\n",
    "        prmaxday\n",
    "    ), axis=0)\n",
    "    \n",
    "    out_raster_stack = np.empty_like(processed_arrays)\n",
    "\n",
    "    for i in range(processed_arrays.shape[0]):\n",
    "        raster = np.squeeze(processed_arrays[i, :, :])\n",
    "        new_raster = cut_and_paste(raster)\n",
    "        out_raster_stack[i, :, :] = np.squeeze(new_raster)\n",
    "    \n",
    "    return out_raster_stack\n",
    "    \n",
    "%timeit calc(\"historical\", \"ACCESS1-0\", \"1950\", prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
